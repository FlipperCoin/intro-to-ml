{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Itai/source/repos/intro-to-ml/major_hw3/hw3.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Itai/source/repos/intro-to-ml/major_hw3/hw3.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Itai/source/repos/intro-to-ml/major_hw3/hw3.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Itai/source/repos/intro-to-ml/major_hw3/hw3.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_table\u001b[39;00m \u001b[39mimport\u001b[39;00m DataTable\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Itai/source/repos/intro-to-ml/major_hw3/hw3.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Itai/source/repos/intro-to-ml/major_hw3/hw3.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_validate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from google.colab.data_table import DataTable\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=''\n",
    "df = pd.read_csv(filename)\n",
    "train, test=train_test_split(df,test_size=0.2,train_size=0.8,random_state=106)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_create_columns(data):\n",
    "  temp=pd.get_dummies(data.blood_type)\n",
    "  data[\"A blood_type\"]=temp['A+']+temp['A-']\n",
    "  data[\"B or AB blood_type\"]=temp['AB+']+temp['AB-']+temp['B-']+temp['B+']\n",
    "  data[\"O blood_type\"]=temp['O+']+temp['O-']\n",
    "  temp=pd.get_dummies(data.symptoms)\n",
    "  temp=temp.loc[:, ['smell_loss','cough;shortness_of_breath;sore_throat']]\n",
    "  data = pd.concat([data, temp],axis=1)\n",
    "  data['pcr_date'] = pd.to_datetime(data['pcr_date']).astype(int)\n",
    "  data['sex']=np.where(data['sex']=='F',1,0)\n",
    "  data[['Latitude','Longitude']] = data['current_location'].str.split(',', expand=True)\n",
    "  data['Latitude']=data.Latitude.str.strip('(')\n",
    "  data['Latitude']=data.Latitude.str.strip(\"'\")\n",
    "  data['Latitude']=data.Latitude.astype(float)\n",
    "  data['Longitude']=data.Longitude.str.strip(')')\n",
    "  data['Longitude']=data.Longitude.str.strip()\n",
    "  data['Longitude']=data.Longitude.str.strip(\"'\")\n",
    "  data['Longitude'] = data['Longitude'].astype(float)\n",
    "  return data\n",
    "\n",
    "\n",
    "def prepare_data(training_data, new_data):\n",
    "  training_data_c=training_data.copy(deep=True)\n",
    "  new_data_c=new_data.copy(deep=True)\n",
    "  training_data_c=split_and_create_columns(training_data_c)\n",
    "  new_data_c=split_and_create_columns(new_data_c)\n",
    "  for column in training_data_c:\n",
    "    if(column=='age' or column=='Latitude' or column=='Longitude' or column=='num_of_siblings' or column=='happiness_score' or column=='household_income' or column=='sugar_levels' or column=='weight' or column=='PCR_04' or column=='PCR_05' or column=='PCR_06' or column=='PCR_10'):\n",
    "      new_data_c[column]=(new_data_c[column]-training_data_c[column].mean())/training_data_c[column].std()\n",
    "    if(column=='conversations_per_day' or column=='sport_activity' or column=='pcr_date' or column=='PCR_01' or column=='PCR_01' or column=='PCR_02' or column=='PCR_03' or column=='PCR_07' or column=='PCR_08' or column=='PCR_09'):\n",
    "      new_data_c[column]=(new_data_c[column]-training_data_c[column].min())/(training_data_c[column].max()-training_data_c[column].min())\n",
    "      new_data_c[column]=new_data_c[column]*2+(-1)\n",
    "  return new_data_c[['age','sex','weight','A blood_type', 'B or AB blood_type', 'O blood_type', 'Latitude', 'Longitude', 'num_of_siblings',\n",
    " 'happiness_score','household_income','conversations_per_day','sugar_levels','sport_activity','smell_loss',\n",
    " 'cough;shortness_of_breath;sore_throat','pcr_date','PCR_01','PCR_02','PCR_03','PCR_04','PCR_05','PCR_06','PCR_07',\n",
    " 'PCR_08','PCR_09','PCR_10','contamination_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=prepare_data(train,test)\n",
    "train=prepare_data(train,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "class LinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom linear regression model\n",
    "    \"\"\"\n",
    "    def __init__(self, lr: float = 1e-5):\n",
    "        \"\"\"\n",
    "        Initialize an instance of this class.\n",
    "        ** Do not edit this method **\n",
    "\n",
    "        :param lr: the SGD learning rate (step size)\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.batch_size = 32\n",
    "        self.w = None\n",
    "        self.b = 0.0\n",
    "\n",
    "    # Initialize a random weight vector\n",
    "    def init_solution(self, n_features: int):\n",
    "        \"\"\"\n",
    "        Randomize an initial solution (weight vector)\n",
    "        ** Do not edit this method **\n",
    "\n",
    "        :param n_features:\n",
    "        \"\"\"\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(w, b: float, X, y):\n",
    "        \"\"\"\n",
    "        Compute the MSE objective loss.\n",
    "\n",
    "        :param w: weight vector for linear regression; array of shape (n_features,)\n",
    "        :param b: bias scalar for linear regression\n",
    "        :param X: samples for loss computation; array of shape (n_samples, n_features)\n",
    "        :param y: targets for loss computation; array of shape (n_samples,)\n",
    "        :return: the linear regression objective loss (float scalar)\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: complete the loss calculation\n",
    "        loss = (np.linalg.norm(((X.dot(w)+b).reshape(-1)-y))**2)/(y.size)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def gradient(w, b: float, X, y):\n",
    "        \"\"\"\n",
    "        Compute the (analytical) linear regression objective gradient.\n",
    "\n",
    "        :param w: weight vector for linear regression; array of shape (n_features,)\n",
    "        :param b: bias scalar for linear regression\n",
    "        :param X: samples for loss computation; array of shape (n_samples, n_features)\n",
    "        :param y: targets for loss computation; array of shape (n_samples,)\n",
    "        :return: a tuple with (the gradient of the weights, the gradient of the bias)\n",
    "        \"\"\"\n",
    "        # TODO: calculate the analytical gradient w.r.t w and b\n",
    "        g_w = ((X.transpose()).dot(((X.dot(w)+b).reshape(-1)-y)))/(0.5*y.size)\n",
    "        g_b = (((X.dot(w)+b).reshape(-1)-y).sum())/(0.5*y.size)\n",
    "\n",
    "        return g_w, g_b\n",
    "\n",
    "    def fit_with_logs(self, X, y, max_iter: int = 1000, keep_losses: bool = True,\n",
    "                      X_val  =None, y_val = None):\n",
    "        \"\"\"\n",
    "        Fit the model according to the given training data.\n",
    "\n",
    "        :param X: training samples; array of shape (n_samples, n_features)\n",
    "        :param y: training targets; array of shape (n_samples,)\n",
    "        :param max_iter: number of SGD iterations\n",
    "        :param keep_losses: should compute the train & val losses during training?\n",
    "        :param X_val: validation samples to compute the loss for (for logs only)\n",
    "        :param y_val: validation labels to compute the loss for (for logs only)\n",
    "        :return: training and validation losses during training\n",
    "        \"\"\"\n",
    "        # Initialize learned parameters\n",
    "        self.init_solution(X.shape[1])\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        if keep_losses:\n",
    "            train_losses.append(self.loss(self.w, self.b, X, y))\n",
    "            val_losses.append(self.loss(self.w, self.b, X_val, y_val))\n",
    "\n",
    "        # Iterate over batches (SGD)\n",
    "        for itr in range(0, max_iter):\n",
    "            start_idx = (itr * self.batch_size) % X.shape[0]\n",
    "            end_idx = min(X.shape[0], start_idx + self.batch_size)\n",
    "            batch_X = X[start_idx: end_idx]\n",
    "            batch_y = y[start_idx: end_idx]\n",
    "\n",
    "            # TODO: Compute the gradient for the current *batch*\n",
    "            g_w, g_b = self.gradient(self.w,self.b,batch_X,batch_y)\n",
    "\n",
    "            # Perform a gradient step\n",
    "            # TODO: update the learned parameters correctly\n",
    "            self.w = self.w - self.lr*g_w\n",
    "            self.b = self.b - self.lr*g_b\n",
    "\n",
    "            if keep_losses:\n",
    "                train_losses.append(self.loss(self.w, self.b,  X, y))\n",
    "                val_losses.append(self.loss(self.w, self.b,  X_val, y_val))\n",
    "\n",
    "        return train_losses, val_losses\n",
    "\n",
    "    def fit(self, X, y, max_iter: int = 1000):\n",
    "        \"\"\"\n",
    "        Fit the model according to the given training data.\n",
    "        ** Do not edit this method **\n",
    "\n",
    "        :param X: training samples; array of shape (n_samples, n_features)\n",
    "        :param y: training targets; array of shape (n_samples,)\n",
    "        :param max_iter: number of SGD iterations\n",
    "        \"\"\"\n",
    "        self.fit_with_logs(X, y, max_iter=max_iter, keep_losses=False)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Regress labels on samples in X.\n",
    "\n",
    "        :param X: samples for prediction; array of shape (n_samples, n_features)\n",
    "        :return: Predicted continuous labels for samples in X; array of shape (n_samples,)\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Compute\n",
    "        y_pred = (X.dot(self.w) + self.b).reshape(-1)\n",
    "\n",
    "        return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
